

	
@article{citeulike:918524,
	abstract = {Upper bounds are found for the masses of most of the new; unobserved particles in unified gauge theories by requiring that the partial-wave amplitudes satisfy unitarity bounds.},
	author = {Dicus, Duane  A.  and Mathur, Vishnu  S. },
	citeulike-article-id = {918524},
	doi = {10.1103/PhysRevD.7.3111},
	journal = {Physical Review D},
	keywords = {higgs},
	month = {May},
	number = {10},
	pages = {3111+},
	priority = {2},
	publisher = {American Physical Society},
	title = {Upper Bounds on the Values of Masses in Unified Gauge Theories},
	url = {http://dx.doi.org/10.1103/PhysRevD.7.3111},
	volume = {7},
	year = {1973}
}



@misc{citeulike:681336,
	abstract = {I provide a pedagogical introduction to supersymmetry. The level of
discussion is aimed at readers who are familiar with the Standard Model and
quantum field theory, but who have had little or no prior exposure to
supersymmetry. Topics covered include: motivations for supersymmetry, the
construction of supersymmetric Lagrangians, supersymmetry-breaking
interactions, the Minimal Supersymmetric Standard Model (MSSM), R-parity and
its consequences, the origins of supersymmetry breaking, the mass spectrum of
the MSSM, decays of supersymmetric particles, experimental signals for
supersymmetry, and some extensions of the minimal framework.},
	author = {Martin, Stephen  P. },
	citeulike-article-id = {681336},
	eprint = {hep-ph/9709356},
	keywords = {supersymmetry},
	month = {Jun},
	priority = {2},
	title = {A Supersymmetry Primer},
	url = {http://arxiv.org/abs/hep-ph/9709356},
	year = {2006}
}



@article{citeulike:918519,
	abstract = {Not Available},
	author = {Higgs, P. W. },
	citeulike-article-id = {918519},
	doi = {10.1016/0031-9163(64)91136-9},
	journal = {Physics Letters},
	keywords = {higgs},
	month = {September},
	pages = {132--133},
	priority = {2},
	title = {Broken symmetries, massless particlees and gauge fields},
	url = {http://dx.doi.org/10.1016/0031-9163(64)91136-9},
	volume = {12},
	year = {1964}
}



@misc{citeulike:912522,
	abstract = {This paper describes DIRAC, the LHCb Monte Carlo production system. DIRAC has
a client/server architecture based on: Compute elements distributed among the
collaborating institutes; Databases for production management, bookkeeping (the
metadata catalogue) and software configuration; Monitoring and cataloguing
services for updating and accessing the databases. Locally installed software
agents implemented in Python monitor the local batch queue, interrogate the
production database for any outstanding production requests using the XML-RPC
protocol and initiate the job submission. The agent checks and, if necessary,
installs any required software automatically. After the job has processed the
events, the agent transfers the output data and updates the metadata catalogue.
DIRAC has been successfully installed at 18 collaborating institutes, including
the DataGRID, and has been used in recent Physics Data Challenges. In the near
to medium term future we must use a mixed environment with different types of
grid middleware or no middleware. We describe how this flexibility has been
achieved and how ubiquitously available grid middleware would improve DIRAC.},
	author = {Brook, N.  and Bogdanchikov, A.  and Buckley, A.  and Closier, J.  and Egede, U.  and Frank, M.  and Galli, D.  and Gandelman, M.  and Garonne, V.  and Gaspar, C.  and  and Harrison, K.  and van Herwijnen, E.  and Khan, A.  and Klous, S.  and Korolko, I.  and Kuznetsov, G.  and Loverre, F.  and Marconi, U.  and Palacios, J. P.  and Patrick, G. N.  and Pickford, A.  and Ponce, S.  and Romanovski, V.  and Saborido, J. J.  and Schmelling, M.  and Soroko, A.  and Tsaregorodtsev, A.  and Vagnoni, V.  and Washbrook, A. },
	citeulike-article-id = {912522},
	eprint = {cs.dc/0306060},
	keywords = {computing},
	month = {Jun},
	priority = {2},
	title = {DIRAC - Distributed Infrastructure with Remote Agent Control},
	url = {http://arxiv.org/abs/cs.dc/0306060},
	year = {2003}
}



@article{citeulike:912514,
	abstract = {AliEn (http://alien.cern.ch) (ALICE Environment) is a Grid framework built on top of the latest Internet standards for information exchange and authentication (SOAP, PKI) and common Open Source components. AliEn provides a virtual file catalogue that allows transparent access to distributed datasets and a number of collaborating Web services which implement the authentication, job execution, file transport, performance monitor and event logging. In the paper we will present the architecture and components of the system.},
	author = {Saiz, P.  and Aphecetche, L.  and Buncic, P.  and Piskac, R.  and  and Sego, V. },
	booktitle = {Proceedings of the VIII International Workshop on Advanced Computing and Analysis Techniques in Physics Research},
	citeulike-article-id = {912514},
	doi = {10.1016/S0168-9002(03)00462-5},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	keywords = {computing},
	month = {April},
	number = {2-3},
	pages = {437--440},
	priority = {2},
	title = {AliEn--ALICE environment on the GRID},
	url = {http://www.sciencedirect.com/science/article/B6TJM-480C1TX-13/2/5eb76d3bf340c5df764790cf56e96c38},
	volume = {502},
	year = {2003}
}



@misc{citeulike:912507,
	abstract = {The Gaudi/Athena and Grid Alliance (GANGA) is a front-end for the
configuration, submission, monitoring, bookkeeping, output collection, and
reporting of computing jobs run on a local batch system or on the grid. In
particular, GANGA handles jobs that use applications written for the Gaudi
software framework shared by the Atlas and LHCb experiments. GANGA exploits the
commonality of Gaudi-based computing jobs, while insulating against grid-,
batch- and framework-specific technicalities, to maximize end-user productivity
in defining, configuring, and executing jobs. Designed for a python-based
component architecture, GANGA has a modular underpinning and is therefore well
placed for contributing to, and benefiting from, work in related projects. Its
functionality is accessible both from a scriptable command-line interface, for
expert users and automated tasks, and through a graphical interface, which
simplifies the interaction with GANGA for beginning and c1asual users.
<br />This paper presents the GANGA design and implementation, the development of
the underlying software bus architecture, and the functionality of the first
public GANGA release.},
	author = {Harrison, K.  and Lavrijsen, W. T. L. P.  and Mato, P.  and Soroko, A.  and Tan, C. L.  and Tull, C. E.  and Brook, N.  and Jones, R. W. L. },
	citeulike-article-id = {912507},
	eprint = {cs.se/0306085},
	keywords = {computing},
	month = {Jun},
	priority = {2},
	title = {GANGA: a user-Grid interface for Atlas and LHCb},
	url = {http://arxiv.org/abs/cs.se/0306085},
	year = {2003}
}



@inproceedings{citeulike:912501,
	author = {Branco, M. },
	booktitle = {of CHEP04, Interlaken, Switzerland},
	citeulike-article-id = {912501},
	keywords = {computing},
	priority = {2},
	title = {Don Quijote - Data Management for the ATLAS Automatic Production System},
	url = {http://indico.cern.ch/contribAuthorDisplay.py?authorId=branco m. miguel.branco@cern.ch\&#38;confId=0}
}



@inproceedings{citeulike:912497,
	author = {Rehn, J. },
	booktitle = {of CHEP06, Mumbai, India},
	citeulike-article-id = {912497},
	keywords = {cms computing},
	priority = {2},
	title = {PhEDEx high-throughput data transfer management system},
	year = {2006}
}



@misc{citeulike:912494,
	citeulike-article-id = {912494},
	journal = {http://cdinternal.fnal.gov/RUNIIRev/runIIMP05.asp},
	keywords = {computing},
	priority = {2},
	title = {RunII Computing Review},
	url = {http://cdinternal.fnal.gov/RUNIIRev/runIIMP05.asp}
}



@inproceedings{citeulike:905688,
	author = {Bityukov, S. I.  and Erofeeva, S. E.  and Krasnikov, N. V.  and Nikitenko, A. },
	booktitle = {of PhyStat},
	citeulike-article-id = {905688},
	keywords = {cms},
	priority = {2},
	title = {Program for evaluation of significance, confidence intervals and limits by direct calcualtion of probabilities.},
	url = {http://www.physics.ox.ac.uk/phystat05/proceedings/files/bityukov-talk2_final.pdf},
	year = {2005}
}



@misc{citeulike:905609,
	abstract = {FeynHiggs is a Fortran code for the calculation of the masses of the neutral
CP-even Higgs bosons in the MSSM up to two-loop order. It is based on the
complete diagrammatic on-shell results at the one-loop level, the leading
diagrammatic two-loop QCD contributions and further improvements taking into
account leading electroweak two-loop and leading higher-order QCD corrections.
The Higgs-boson masses are calculated as functions of the MSSM parameters for
general mixing in the scalar top sector and arbitrary choices of the parameters
in the Higgs sector of the model.},
	author = {Heinemeyer, S.  and Hollik, W.  and Weiglein, G. },
	citeulike-article-id = {905609},
	eprint = {hep-ph/9812320},
	keywords = {cms},
	month = {Dec},
	priority = {2},
	title = {FeynHiggs: a program for the calculation of the masses of the neutral CP-even Higgs bosons in the MSSM},
	url = {http://arxiv.org/abs/hep-ph/9812320},
	year = {1998}
}



@article{citeulike:905602,
	author = {Kalinowski, A.  and Nikitenko, A. },
	citeulike-article-id = {905602},
	journal = {CMS NOTE},
	keywords = {cms},
	priority = {2},
	title = {Measurement of the tua tag efficiency using the Z \rightarrow \tau \tau \rightarrow \mu + hadrons + X events},
	volume = {2006/074}
}



@article{citeulike:905600,
	author = {Nikitenko, A.  and Kunori, S.  and Kinnunen, R. },
	citeulike-article-id = {905600},
	journal = {CMS NOTE},
	keywords = {cms},
	priority = {2},
	title = {Missing Transverse Energy Measurment with Jet Energy Correction},
	volume = {2001/040}
}



@article{citeulike:903868,
	author = {Heister, A.  and Al, Et  },
	citeulike-article-id = {903868},
	journal = {CMS NOTE},
	keywords = {cms},
	priority = {2},
	title = {Jet reconstruction and performance in the CMS detector},
	volume = {2006-036}
}



@article{citeulike:903864,
	author = {Gennai, S.  and Nikitenko, A.  and Wndland, L. },
	citeulike-article-id = {903864},
	journal = {CMS NOTE},
	keywords = {higgs},
	priority = {2},
	title = {Search for MSSM heavy netral Higgs boson in the tau tat -> two jet decay mode},
	volume = {2006-126}
}



@article{citeulike:903857,
	abstract = {<A HREF="/cgi-bin/nph-data_query?link_type=EJOURNAL\&bibcode=1993CoPhC..76..361J">Electronic Article Available</A> from <A HREF="http://www.elsevier.com">Elsevier Science.</A>},
	author = {Jadach, S.  and Ws, Z.  and Decker, R.  and K{\"uhn}, J. H. },
	citeulike-article-id = {903857},
	doi = {10.1016/0010-4655(93)90061-G},
	journal = {Computer Physics Communications},
	keywords = {computing},
	month = {August},
	pages = {361--380},
	priority = {2},
	title = {The {$\tau$ decay library TAUOLA, version 2.4}},
	url = {http://dx.doi.org/10.1016/0010-4655(93)90061-G},
	volume = {76},
	year = {1993}
}



@misc{citeulike:903853,
	abstract = {PYTHIA version 6 represents a merger of the PYTHIA 5, JETSET 7 and SPYTHIA
programs, with many improvements. It can be used to generate
high-energy-physics `events', i.e. sets of outgoing particles produced in the
interactions between two incoming particles. The objective is to provide as
accurate as possible a representation of event properties in a wide range of
reactions. The underlying physics is not understood well enough to give an
exact description; the programs therefore contain a combination of analytical
results and various models. The emphasis in this article is on new aspects, but
a few words of general introduction are included. Further documentation is
available on the web.},
	author = {Sj{\"o}strand, Torbj{\"o}rn   and Ed\&eacute;n, Patrik   and Friberg, Christer   and L{\"o}nnblad, Leif   and Miu, Gabriela   and Mrenna, Stephen   and Norrbin, Emanuel  },
	citeulike-article-id = {903853},
	eprint = {hep-ph/0010017},
	keywords = {computing},
	month = {Oct},
	priority = {2},
	title = {High-Energy-Physics Event Generation with PYTHIA 6.1},
	url = {http://arxiv.org/abs/hep-ph/0010017},
	year = {2000}
}



@article{citeulike:903780,
	author = {Seez, C. },
	citeulike-article-id = {903780},
	doi = {10.1140/epjcd/s2004-04-016-8},
	journal = {The European Physical Journal},
	keywords = {cms},
	number = {34},
	pages = {s1.151--s1.159},
	priority = {2},
	title = {The CMS trigger system},
	url = {http://www.edpsciences.org/articles/epjc/abs/2004/30/10052_2004_Article_1914/10052_2004_Article_1914.html},
	volume = {C},
	year = {2004}
}



@article{CMS_TDR_PHYS_vol2,
	author = {Collaboration, C. M. S. },
	citeulike-article-id = {903675},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 8.2},
	priority = {2},
	title = {The CMS Physics Technical Design Report, Volume 2},
	volume = {2006/021}
}



@article{citeulike:899448,
	citeulike-article-id = {899448},
	journal = {http://pool.cern.ch/},
	keywords = {no-tag},
	priority = {2},
	title = {LHC Persistency framework, Pool Of persistent Objects for LHC}
}



@article{citeulike:899447,
	booktitle = {http://public.eu-egee.org/},
	citeulike-article-id = {899447},
	keywords = {no-tag},
	priority = {2},
	title = {Enabling Grids for E-sciencE (EGEE)}
}



@misc{citeulike:899441,
	booktitle = {http://eu-datagrid.web.cern.ch/eu-datagrid/},
	citeulike-article-id = {899441},
	keywords = {no-tag},
	priority = {2},
	title = {European DataGrid Project (EDG)}
}



@misc{citeulike:894146,
	abstract = {The Higgs boson search has shifted from LEP2 to the Tevatron and will
subsequently move to the LHC. The current limits from the Tevatron and the
prospective sensitivities at the LHC are often interpreted in specific MSSM
scenarios. For heavy Higgs boson production and subsequent decay into b \bar b
or tau^+ tau^-, the present Tevatron data allow to set limits in the
M_A-tan_beta plane for small M_A and large tan_beta values. Similar channels
have been explored for the LHC, where the discovery reach extends to higher
values of M_A and smaller tan_beta. Searches for MSSM charged Higgs bosons,
produced in top decays or in association with top quarks, have also been
investigated at the Tevatron and the LHC. We analyze the current Tevatron
limits and prospective LHC sensitivities. We discuss how robust they are with
respect to variations of the other MSSM parameters and possible improvements of
the theoretical predictions for Higgs boson production and decay. It is shown
that the inclusion of supersymmetric radiative corrections to the production
cross sections and decay widths leads to important modifications of the present
limits on the MSSM parameter space. The impact on the region where only the
lightest MSSM Higgs boson can be detected at the LHC is also analyzed. We
propose to extend the existing benchmark scenarios by including additional
values of the higgsino mass parameter mu. This affects only slightly the search
channels for a SM-like Higgs boson, while having a major impact on the searches
for non-standard MSSM Higgs bosons.},
	author = {Carena, M.  and Heinemeyer, S.  and Wagner, C. E. M.  and Weiglein, G. },
	citeulike-article-id = {894146},
	eprint = {hep-ph/0511023},
	keywords = {higgs supersymmetry},
	month = {Nov},
	priority = {2},
	title = {MSSM Higgs Boson Searches at the Tevatron and the LHC: Impact of Different Benchmark Scenarios},
	url = {http://arxiv.org/abs/hep-ph/0511023},
	year = {2005}
}



@misc{citeulike:891490,
	abstract = {We present cross sections and differential distributions for QCD radiative
corrections to the QCD processes pp -\&gt; W+2j and pp -\&gt; Z+2j at the CERN LHC.
Calculations are performed with the Monte Carlo program MCFM. Cross section
dependence on the renormalization and factorization scales is greatly reduced,
except for the heavy-flavor case of Wbb~, which has new features at
next-to-leading order at the LHC. We also present cross sections for Wbb~ and
Z+2j in kinematic configurations relevant for Higgs boson searches.},
	author = {Campbell, John   and Ellis, R. K.  and Rainwater, D. },
	citeulike-article-id = {891490},
	eprint = {hep-ph/0308195},
	keywords = {cms},
	month = {Nov},
	priority = {2},
	title = {Next-to-leading order QCD predictions for W+2j and Z+2j production at the CERN LHC},
	url = {http://arxiv.org/abs/hep-ph/0308195},
	year = {2003}
}



@misc{citeulike:890218,
	abstract = {The second part of this review is devoted to the Higgs sector of the Minimal
Supersymmetric Standard Model. The properties of the neutral and charged Higgs
bosons of the extended Higgs sector are summarized and their decay modes and
production mechanisms at hadron colliders and at future lepton colliders are
reviewed.},
	author = {Djouadi, Abdelhak  },
	citeulike-article-id = {890218},
	eprint = {hep-ph/0503173},
	keywords = {higgs supersymmetry},
	month = {May},
	priority = {2},
	title = {The Anatomy of Electro-Weak Symmetry Breaking. II: The Higgs bosons in the Minimal Supersymmetric Model},
	url = {http://arxiv.org/abs/hep-ph/0503173},
	year = {2005}
}



@misc{citeulike:888485,
	abstract = {Precision electroweak data presently favors a weakly-coupled Higgs sector as
the mechanism responsible for electroweak symmetry breaking. Low-energy
supersymmetry provides a natural framework for weakly-coupled elementary
scalars. In this review, we summarize the theoretical properties of the
Standard Model (SM) Higgs boson and the Higgs sector of the minimal
supersymmetric extension of the Standard Model (MSSM). We then survey the
phenomenology of the SM and MSSM Higgs bosons at the Tevatron, LHC and a future
e+e- linear collider. We focus on the Higgs discovery potential of present and
future colliders and stress the importance of precision measurements of Higgs
boson properties.},
	author = {Carena, Marcela   and Haber, Howard  E. },
	citeulike-article-id = {888485},
	eprint = {hep-ph/0208209},
	keywords = {higgs},
	month = {Dec},
	priority = {2},
	title = {Higgs Boson Theory and Phenomenology},
	url = {http://arxiv.org/abs/hep-ph/0208209},
	year = {2002}
}



@article{citeulike:888474,
	author = {Gennai, S.  and Nikitenko, A.  and Wendland, L. },
	citeulike-article-id = {888474},
	journal = {CMS NOTE-2006/126},
	keywords = {cms higgs supersymmetry},
	priority = {2},
	title = {Search for MSSM heavy Higgs boson in tau tau -> two jet decay mode.}
}



@misc{citeulike:888436,
	abstract = {In the year 2000 the four LEP experiments collected data at centre-of-mass
energies between 200 and 209 GeV, integrating approximately 870 pb-1 of
luminosity, with about 510 pb-1 above 206 GeV. The LEP working group for Higgs
boson searches has combined these data with data sets collected previously at
lower energies. In representative scans of the parameters of the Minimal
Supersymmetric Standard Model (MSSM), the mass limits mh\&gt;91.0 GeV and mA\&gt;91.9
GeV are obtained for the light CP-even and the CP-odd neutral Higgs boson,
respectively. For a top quark mass less than or equal to 174.3 GeV, assuming
that the stop quark mixing is maximal, and choosing conservative values for
other SUSY parameters affecting the Higgs sector, the range 0.5\&lt;tanbeta\&lt;2.4 is
excluded. Additionally, the results of flavour-independent searches for
hadronically decaying Higgs bosons are included, allowing exclusion of MSSM
models with suppressed decays of the Higgs bosons to pairs of b quarks.},
	author = {Collaboration, Aleph   and Collaboration, Delphi   and Collaboration, L3   and Collaboration, O. P. A. L.  and },
	citeulike-article-id = {888436},
	eprint = {hep-ex/0107030},
	keywords = {higgs supersymmetry},
	month = {Jul},
	priority = {2},
	title = {Searches for the Neutral Higgs Bosons of the MSSM: Preliminary Combined Results Using LEP Data Collected at Energies up to 209 GeV},
	url = {http://arxiv.org/abs/hep-ex/0107030},
	year = {2001}
}



@article{pdg2006,
	author = {Yao, W. M.  and Al, Et  },
	citeulike-article-id = {882746},
	journal = {Journal of Physics G},
	keywords = {no-tag},
	pages = {1+},
	priority = {2},
	title = {Review of Particle Physics},
	volume = {33},
	year = {2006}
}



@inproceedings{citeulike:881635,
	author = {Geus, R.  and Skavhaug, O.  and },
	booktitle = {EuroPython 2004 Conference, Gothenburg, Sweden},
	citeulike-article-id = {881635},
	keywords = {computing},
	priority = {2},
	title = {Python Wrapper Tools; a Performance Study}
}



@article{citeulike:881616,
	author = {Abrahams, David   and Grosse-Kunstleve, Ralf  W. },
	citeulike-article-id = {881616},
	journal = {C/C++ Users Journal},
	keywords = {computing},
	month = {July},
	number = {7},
	priority = {1},
	title = {Building Hybrid Systems with Boost. Python},
	url = {http://www.osti.gov/energycitations/product.biblio.jsp?osti_id=815409},
	volume = {21},
	year = {2003}
}



@misc{citeulike:881611,
	citeulike-article-id = {881611},
	keywords = {computing},
	priority = {1},
	title = {http://www.riverbankcomputing.co.uk/sip/}
}



@article{citeulike:881608,
	address = {Amsterdam, The Netherlands, The Netherlands},
	author = {Beazley, D. M. },
	citeulike-article-id = {881608},
	doi = {10.1016/S0167-739X(02)00171-1},
	journal = {Future Gener. Comput. Syst.},
	keywords = {computing},
	month = {July},
	number = {5},
	pages = {599--609},
	priority = {2},
	publisher = {Elsevier Science Publishers B. V.},
	title = {Automated scientific software scripting with SWIG},
	url = {http://dx.doi.org/10.1016/S0167-739X(02)00171-1},
	volume = {19},
	year = {2003}
}



@inproceedings{citeulike:880984,
	author = {Bacchi, W.  and Codiispoti, G.  and Grandi, C.  and Colling, D.  and Macevoy, B.  and Wakefield, S.  and Zhang, Y. },
	booktitle = {Proceedings of CHEP06, Mumbai},
	citeulike-article-id = {880984},
	keywords = {boss cms computing},
	priority = {2},
	title = {Evolution of BOSS, A tool for job submission and tracking},
	year = {2006}
}



@inproceedings{citeulike:880975,
	abstract = {The MonALISA (Monitoring Agents in A Large Integrated Services Architecture) system provides a distributed monitoring service. MonALISA is based on a scalable Dynamic Distributed Services Architecture which is designed to meet the needs of physics collaborations for monitoring global Grid systems, and is implemented using JINI/JAVA and WSDL/SOAP technologies. The scalability of the system derives from the use of multithreaded Station Servers to host a variety of loosely coupled self-describing dynamic services, the ability of each service to register itself and then to be discovered and used by any other services, or clients that require such information, and the ability of all services and clients subscribing to a set of events (state changes) in the system to be notified automatically. The framework integrates several existing monitoring tools and procedures to collect parameters describing computational nodes, applications and network performance. It has built-in SNMP support and network-performance monitoring algorithms that enable it to monitor end-to-end network performance as well as the performance and state of site facilities in a Grid. MonALISA is currently running around the clock on the US CMS test Grid as well as an increasing number of other sites. It is also being used to monitor the performance and optimize the interconnections among the reflectors in the VRVS system.},
	author = {Newman, H. B.  and Legrand, I. C.  and Galvez, P.  and Voicu, R.  and Cirstoiu, C. },
	booktitle = {Proceedings of CHEP03},
	citeulike-article-id = {880975},
	eprint = {cs.DC/0306096},
	keywords = {cms computing},
	month = {Jun},
	priority = {2},
	title = {MonALISA : A Distributed Monitoring Service Architecture},
	url = {http://arxiv.org/abs/cs.DC/0306096},
	year = {2003}
}



@manual{citeulike:878837,
	author = {Tallini, H.  and Wakefield, S. },
	citeulike-article-id = {878837},
	howpublished = {avaialable from http://www.hep.ph.ic.ac.uk/e-science/projects/downloads.html},
	keywords = {computing gross},
	priority = {2},
	title = {GROSS 0.4.0 User and Installation Guide.}
}



@misc{citeulike:877254,
	abstract = {Starting in the middle of November 2002, the CMS experiment undertook an
evaluation of the European DataGrid Project (EDG) middleware using its event
simulation programs. A joint CMS-EDG task force performed a "stress test" by
submitting a large number of jobs to many distributed sites. The EDG testbed
was complemented with additional CMS-dedicated resources. A total of ~ 10000
jobs consisting of two different computational types were submitted from four
different locations in Europe over a period of about one month. Nine sites were
active, providing integrated resources of more than 500 CPUs and about 5 TB of
disk space (with the additional use of two Mass Storage Systems). Descriptions
of the adopted procedures, the problems encountered and the corresponding
solutions are reported. Results and evaluations of the test, both from the CMS
and the EDG perspectives, are described.},
	author = {Bonacorsi, D.  and Capiluppi, P.  and Fanfani, A.  and Grandi, C.  and Corvo, M.  and Fanzago, F.  and Sgaravatto, M.  and Verlato, M.  and Charlot, C.  and Semeniuok, I.  and Colling, D.  and Macevoy, B.  and Tallini, H.  and Biasotto, M.  and Fantinel, S.  and Leonardi, E.  and Sciaba', A.  and Maroney, O.  and Augustin, I.  and Laure, E.  and Schulz, M.  and Stockinger, H.  and Lefebure, V.  and Burke, S.  and Blaising, J. J.  and Templon, J.  and Reale, M.  and Tortone, G.  and Prelz, F.  and Loomis, C. },
	citeulike-article-id = {877254},
	eprint = {physics/0306038},
	keywords = {cms computing},
	month = {Jun},
	priority = {2},
	title = {Running CMS software on GRID Testbeds},
	url = {http://arxiv.org/abs/physics/0306038},
	year = {2003}
}



@inproceedings{citeulike:876402,
	author = {Wynhoff, S. },
	booktitle = {Proceedings of CHEP04, Interlaken, Switzerland},
	citeulike-article-id = {876402},
	keywords = {cms computing},
	priority = {2},
	title = {Using the reconstruction software, ORCA, in the CMS datachallenge 2004},
	year = {2004}
}



@inproceedings{citeulike:876380,
	author = {Corvo, M. },
	booktitle = {Proceedings of CHEP06, Mumbai, India},
	citeulike-article-id = {876380},
	keywords = {cms computing},
	priority = {2},
	title = {CRAB: a tool to enable CMS Distributed Analysis},
	year = {2006}
}



@article{citeulike:876074,
	abstract = {In Spring 2004, CMS will undertake a 100 TeraByte-scale Data Challenge (DC04) as part of a series of challenges in preparation for running at CERN's Large Hadron Collider. During 1 month, DC04 must demonstrate the ability of the computing and software to cope with a sustained event data-taking rate of 25 Hz, for a total of 50 million events. The emphasis of DC04 is on the validation of the first pass reconstruction and storage systems at CERN and the streaming of events to a distributed system of Tier-1, and Tier-2 sites worldwide where typical analysis tasks will be performed. It is expected that the LHC Computing Grid project will provide a set of grid services suitable for use in a real production environment, as part of this data challenge. The results of this challenge will be used to define the CMS software and computing systems in their Technical Design Report.},
	author = {Grandi, C. },
	booktitle = {Proceedings of the IXth International Workshop on Advanced Computing and Analysis Techniques in Physics Research},
	citeulike-article-id = {876074},
	doi = {10.1016/j.nima.2004.07.065},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	keywords = {cms computing dc04},
	month = {November},
	number = {1-2},
	pages = {87--93},
	priority = {2},
	title = {CMS distributed data analysis challenges},
	url = {http://dx.doi.org/10.1016/j.nima.2004.07.065},
	volume = {534},
	year = {2004}
}



@misc{citeulike:867593,
	abstract = {McRunjob is a powerful grid workflow manager used to manage the generation of
large numbers of production processing jobs in High Energy Physics. In use at
both the DZero and CMS experiments, McRunjob has been used to manage large
Monte Carlo production processing since 1999 and is being extended to uses in
regular production processing for analysis and reconstruction. Described at
CHEP 2001, McRunjob converts core metadata into jobs submittable in a variety
of environments. The powerful core metadata description language includes
methods for converting the metadata into persistent forms, job descriptions,
multi-step workflows, and data provenance information. The language features
allow for structure in the metadata by including full expressions, namespaces,
functional dependencies, site specific parameters in a grid environment, and
ontological definitions. It also has simple control structures for
parallelization of large jobs. McRunjob features a modular design which allows
for easy expansion to new job description languages or new application level
tasks.},
	author = {Graham, Gregory  E.  and Evans, Dave   and Bertram, Iain  },
	citeulike-article-id = {867593},
	eprint = {cs.DC/0305063},
	keywords = {cms computing},
	month = {Jun},
	priority = {2},
	title = {McRunjob: A High Energy Physics Workflow Planner for Grid Production Processing},
	url = {http://arxiv.org/abs/cs.DC/0305063},
	year = {2003}
}



@misc{run2_comp_review,
	citeulike-article-id = {851127},
	howpublished = {http://cdinternal.fnal.gov/RUNIIRev/runIIMP05.asp},
	keywords = {cdf dzero},
	priority = {2},
	title = {Run II Computing Review 2005}
}



@misc{citeulike:850908,
	abstract = {The achievable precision of the cross section times branching ratio
measurement from the event rates is estimated for the MSSM H/A -\&gt; tau tau decay
in the associated production process gg -\&gt; b bbar H/A at large tan beta in CMS.
This work demonstrates that the above production and decay process exhibit a
large sensitivity to tan beta and thus add as a significant observable to a
global fit of the SUSY parameters. To illustrate this potential an example is
given concerning the achievable tan beta determination accuracy that could be
reached from the event rates and for a given set of SUSY parameters and
uncertainties.},
	author = {Kinnunen, R.  and Lehti, S.  and Moortgat, F.  and Nikitenko, A.  and Spira, M. },
	citeulike-article-id = {850908},
	eprint = {hep-ph/0503075},
	keywords = {cms higgs tau},
	month = {Mar},
	priority = {2},
	title = {Measurement of the H/A -\&gt; tau tau cross section and possible  constraints on tan beta},
	url = {http://arxiv.org/abs/hep-ph/0503075},
	year = {2005}
}



@article{d0,
	abstract = {The DO detector is a large general purpose detector for the study of short-distance phenomena in high energy antiproton-proton collisions, now in operation at the Fermilab Tevatron collider. The detector focusses upon the detection of electrons, muons, jets and missing transverse momentum. We describe the design and performance of the major elements of the detector, including the tracking chambers, transition radiation detector, liquid argon calorimetry and muon detection. The associated electronics, triggering systems and data acquisition systems are presented. The global mechanical, high voltage, and experiment monitoring and control systems which support the detector are described. We also discuss the design and implementation of software and software support systems that are specific to DO.},
	citeulike-article-id = {848632},
	doi = {10.1016/0168-9002(94)91312-9},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	keywords = {dzero},
	month = {January},
	number = {2-3},
	pages = {185--253},
	priority = {2},
	title = {The DO detector},
	url = {http://dx.doi.org/10.1016/0168-9002(94)91312-9},
	volume = {338},
	year = {1994}
}



@article{cdf,
	abstract = {The Collider Detector at Fermilab (CDF) is a 5000 t magnetic detector built to study collisions at the Fermilab Tevatron. Event analysis is based on charged particle tracking, magnetic momentum analysis and fine-grained calorimetry. The combined electromagnetic and hadron calorimetry has approximately uniform granularity in rapidity-azimuthal angle and extends down to 2[deg] from the beam direction. Various tracking chambers cover the calorimeter acceptance and extend charged particle tracking down to 2 mrad from the beam direction. Charged particle momenta are analyzed in a 1.5 T solenoidal magnetic field, generated by a superconducting coil which is 3 m in diameter and 5 m in length. The central tracking chamber measures particle momenta with a resolution better then [delta]pT/pT2 = 2 x 10-3 (GeV/c)-1 in the region 40[deg] PT/pT2 -3 for 21[deg] < [theta] < 40[deg] and 140[deg] < [theta] < 159[deg]. The calorimetry, which has polar angle coverage from 2[deg] to 178[deg] and full azimuthal coverage, consists of electromagnetic shower counters and hadron calorimeters, and is segmented into about 5000 projective "towers" or solid angle elements. Muon coverage is provided by drift chambers in the region 56[deg] < [theta] < 124[deg], and by large forward toroid systems in the range 3[deg] < [theta] < 16[deg] and 164[deg] < [theta] < 177[deg]. Isolated high momentum muons can be identified in the intermediate angular range by a comparison of the tracking and calorimeter information in many cases. A custom front-end electronics system followed by a large Fastbus network provides the readout of the approximately 100 000 detector channels. Fast Level 1 and Level 2 triggers make a detailed pre-analysis of calorimetry and tracking information; a Level 3 system of on-line processors will do parallel processing of events. This paper provides a summary of the aspects of the detector which are relevant to its physics capabilities, with references to more detailed descriptions of the subsystems.},
	author = {Abe, F.  and Amidei, D.  and Apollinari, G.  and Ascoli, G.  and Atac, M.  and Auchincloss, P.  and Baden, A. R.  and Barbaro-Galtieri, A.  and Barnes, V. E.  and Barsotti, E. },
	citeulike-article-id = {848622},
	doi = {10.1016/0168-9002(88)90298-7},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	keywords = {cdf},
	month = {September},
	number = {3},
	pages = {387--403},
	priority = {2},
	title = {The CDF detector: an overview},
	url = {http://dx.doi.org/10.1016/0168-9002(88)90298-7},
	volume = {271},
	year = {1988}
}



@misc{citeulike:847987,
	citeulike-article-id = {847987},
	journal = {see http://www.spec.org/},
	keywords = {computing},
	priority = {2},
	title = {SPECINT2000}
}



@article{root,
	abstract = {The ROOT system in an Object Oriented framework for large scale data analysis. ROOT written in C++, contains, among others, an efficient hierarchical OO database, a C++ interpreter, advanced statistical analysis (multi-dimensional histogramming, fitting, minimization, cluster finding algorithms) and visualization tools. The user interacts with ROOT via a graphical user interface, the command line or batch scripts. The command and scripting language is C++ (using the interpreter) and large scripts can be compiled and dynamically linked in. The OO database design has been optimized for parallel access (reading as well as writing) by multiple processes.},
	author = {Brun, Rene   and Rademakers, Fons  },
	booktitle = {New Computing Techniques in Physics Research V},
	citeulike-article-id = {847979},
	doi = {10.1016/S0168-9002(97)00048-X},
	journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	keywords = {computing},
	month = {April},
	number = {1-2},
	pages = {81--86},
	priority = {2},
	title = {ROOT -- An object oriented data analysis framework},
	url = {http://dx.doi.org/10.1016/S0168-9002(97)00048-X},
	volume = {389},
	year = {1997}
}



@manual{citeulike:835507,
	author = {Solomon, M. },
	citeulike-article-id = {835507},
	journal = {http://www.cs.wisc.edu/condor/classad},
	keywords = {computing},
	priority = {2},
	title = {The ClassAd Language Reference Manual,}
}



@misc{citeulike:835506,
	citeulike-article-id = {835506},
	journal = {Located at https://edms. cern. ch/file/454439//LCG-2-UserGuide. pdf},
	keywords = {computing},
	priority = {2},
	title = {LCG-2 User Guide}
}



@article{LCG_TDR,
	citeulike-article-id = {835503},
	keywords = {no-tag},
	priority = {2},
	title = {LHC Computing Grid Technical Design Report},
	url = {http://lcg.web.cern.ch/LCG/tdr/drafts/LCG_TDR_v305.doc}
}



@misc{citeulike:835488,
	citeulike-article-id = {835488},
	keywords = {no-tag},
	priority = {2},
	title = {http://www.mysql.com}
}



@inproceedings{citeulike:833648,
	author = {Anglano, C.  and Barale, S.  and Gaido, L.  and Guarise, A.  and Lusso, S.  and Werbrouck, A.  and Beco, S.  and Pacini, F.  and Terracina, A.  and Maraschini, A.  and Cavalieri, S.  and Monforte, S.  and Donno, F.  and Ghiselli, A.  and Giacomini, F.  and Ronchieri, E.  and Kouril, D.  and Krenek, A.  and Matyska, L.  and Mulac, M.  and Pospisil, J.  and Ruda, M.  and Salvet, Z.  and Sitera, J.  and Visek, J.  and Vocu, M.  and Mezzadri, M.  and Prelz, F.  and Sgaravatto, M.  and Verlato, M. },
	booktitle = {Conference on Computing in High Energy Physics 2001},
	citeulike-article-id = {833648},
	keywords = {grid lcg},
	priority = {2},
	title = {Integrating GRID Tools to Build a Computing Resource Broker: Activities of DataGrid WP1},
	url = {http://www.cnaf.infn.it/~ferrari/papers/myarticles/wp1_chep01.ps}
}



@article{citeulike:421138,
	author = {Faulkner, P. J. W.  and Lowe, L. S.  and Tan, C. L. A.  and Watkins, P. M.  and Bailey, D. S.  and Barrass, T. A.  and Brook, N. H.  and Croft, R. J. H.  and Kelly, M. P.  and Mackay, C. K.  and Metson, S.  and Maroney, O. J. E.  and Newbold, D. M.  and Wilson, F. F.  and Hobson, P. R.  and Khan, A.  and Kyberd, P.  and Nebrensky, J. J.  and Bly, M.  and Brew, C.  and Burke, S.  and Byrom, R.  and Coles, J.  and Cornwall, L. A.  and Djaoui, A.  and Field, L.  and Fisher, S. M.  and Folkes, G. T.  and Geddes, N. I.  and Gordon, J. C.  and Hicks, S. J. C.  and Jensen, J. G.  and Johnson, G.  and Kant, D.  and Kelsey, D. P.  and Kuznetsov, G.  and Leake, J.  and Middleton, R. P.  and Patrick, G. N.  and Prassas, G.  and Saunders, B. J.  and Ross, D.  and Sansum, R. A.  and Shah, T.  and Strong, B.  and Synge, O.  and Tam, R.  and Thorpe, M.  and Traylen, S.  and Wheeler, J. F.  and White, N. G. H.  and Wilson, A. J.  and Antcheva, I.  and Artiaga, E.  and Beringer, J.  and Bird, I. G.  and Casey, J.  and Cass, A. J.  and Chytracek, R.  and Torreira, Gallas  M. V.  and Generowicz, J.  and Girone, M.  and Govi, G.  and Harris, F.  and Heikkurinen, M.  and Horvath, A.  and Knezo, E.  and Litmaath, M.  and Lubeck, M.  and Moscicki, J.  and Neilson, I.  and Poinsignon, E.  and Pokorski, W.  and Ribon, A.  and Sekera, Z.  and Smith, D. H.  and Tomlin, W. L.  and van Eldik, J. E.  and Wojcieszuk, J.  and Brochu, F. M.  and Das, S.  and Harrison, K.  and Hayes, M.  and Hill, J. C.  and Lester, C. G.  and Palmer, M. J.  and Parker, M. A.  and Nelson, M.  and Whalley, M. R.  and Glover, E. W. N.  and Anderson, P.  and Clark, P. J.  and Earl, A. D.  and Holt, A.  and Jackson, A.  and Joo, B.  and Kenway, R. D.  and Maynard, C. M.  and Perry, J.  and Smith, L.  and Wakefield, S. },
	citeulike-article-id = {421138},
	doi = {10.1088/0954-3899/32/1/N01},
	issn = {0954-3899},
	journal = {Journal of Physics G: Nuclear and Particle Physics},
	keywords = {computing grid},
	month = {January},
	number = {1},
	pages = {N1--N20},
	priority = {2},
	publisher = {Institute of Physics Publishing},
	title = {GridPP: development of the UK computing Grid for particle physics},
	url = {http://dx.doi.org/10.1088/0954-3899/32/1/N01},
	volume = {32},
	year = {2006}
}



@book{citeulike:833641,
	author = {Greenberger, M. },
	booktitle = {The Atlantic Monthly},
	citeulike-article-id = {833641},
	keywords = {computing grid},
	priority = {2},
	title = {Computers and the world of the future},
	year = {1962}
}



@article{citeulike:821072,
	abstract = {Protons and antiprotons have been stored simultaneously in the CERN SPS for several hours. Their interactions at 540 GeV in the centre-of-mass system have been observed by three different experiments.},
	author = {},
	citeulike-article-id = {821072},
	doi = {10.1016/0370-2693(81)90836-4},
	journal = {Physics Letters B},
	keywords = {lhc},
	month = {December},
	number = {4},
	pages = {306--309},
	priority = {2},
	title = {First proton-antiproton collisions in the CERN SPS collider},
	url = {http://dx.doi.org/10.1016/0370-2693(81)90836-4},
	volume = {107},
	year = {1981}
}



@article{LHC_CONCEPT,
	author = {},
	citeulike-article-id = {818181},
	journal = {CERN/AC/95-05 (LHC)},
	keywords = {lhc},
	priority = {2},
	title = {The Large Hadron Collider: Conceptual Design},
	year = {1995}
}



@article{CMS_TRKTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816015},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 5, Addendum CERN/LHCC 2000-016},
	priority = {2},
	title = {The Tracker Project Technical Design Report},
	volume = {98-006},
	year = {1998}
}



@article{CMS_ECALTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816013},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 4, Addendum CERN/LHCC 2002-027},
	priority = {2},
	title = {The Electromagnetic Calorimeter Technical Design Report},
	volume = {97-033},
	year = {1997}
}



@article{CMS_MUONTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816012},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 3},
	priority = {2},
	title = {The Muon Project Technical Design Report},
	volume = {97-32},
	year = {1997}
}



@article{CMS_HCALTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816011},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 2},
	priority = {2},
	title = {The Hadron Calorimeter Technical Design Report},
	volume = {97-031},
	year = {1997}
}



@article{CMS_MAGTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816010},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 1},
	priority = {2},
	title = {The Magnet Project Technical Design Report},
	volume = {97-010},
	year = {1997}
}



@article{CMS_DAQTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816009},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 6.2},
	priority = {2},
	title = {The TriDAS Project Technical Design Report, Volume 2: Data Acquisition and High-Level Trigger},
	volume = {2002-26},
	year = {2002}
}



@article{CMS_L1TDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816008},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {CMS TDR 6.1},
	priority = {2},
	title = {The TriDAS Project Technical Design Report, Volume 1: The Trigger Systems},
	volume = {2000-38},
	year = {2000}
}



@article{CMS_TP,
	author = {Collaboration, \cms  },
	citeulike-article-id = {816007},
	journal = {CERN/LHCC},
	keywords = {cms},
	number = {LHCC/P1},
	priority = {2},
	title = {The Compact Muon Solenoid Technical Proposal},
	volume = {94-38},
	year = {1994}
}



@article{CMS_LOI,
	author = {Collaboration, C. M. S. },
	citeulike-article-id = {816005},
	journal = {CERN/LHCC},
	keywords = {cms},
	priority = {2},
	title = {The Compact Muon Solenoid Letter of Intent},
	volume = {LHCC/I 1},
	year = {1992}
}



@article{citeulike:800614,
	abstract = {The tau indentification and reconstruction algorithms developed for the CMS experiment at LHC are presented. The algorithms are aimed to an efficient selection of hadronic decays of the tau lepton. Reconstruction methods suitable for use at the High Level Trigger and off-line are described in detail.},
	author = {Bagliesi, G.  and Dutta, S.  and Gennai, S.  and Kalinowski, A.  and Konecki, M.  and Kotlinski, D.  and Moortgat, F.  and Nikitenko, A.  and Wendland, L.  and Wakefield, S. },
	citeulike-article-id = {800614},
	doi = {10.1140/epjcd/s2006-02-001-y},
	edition = {46},
	journal = {Eur. Phys. J. C.},
	keywords = {cms tau},
	pages = {1--21},
	priority = {0},
	title = {Tau jet reconstruction and tagging with CMS},
	url = {http://www.edpsciences.org/articles/epjc/abs/2006/09/10052_2006_Article_2548/10052_2006_Article_2548.html},
	year = {2006}
}



@article{CMS_NOTE_2006-028,
	abstract = {The Tau identification and reconstruction algorithms are described, from the High Level Trigger to the off-line reconstruction and selection.},
	author = {Bagliesi, G.  and Dutta, S.  and Gennai, S.  and Kalinowski, A.  and Konecki, M.  and Kotlinski, D.  and Moortgat, F.  and Nikitenko, A.  and Wendland, L.  and Wakefield, S. },
	citeulike-article-id = {773256},
	journal = {CMS NOTE-2006/028},
	keywords = {cms tau},
	priority = {2},
	title = {Tau jet reconstruction and tagging at High Level Trigger and off-line}
}



@article{CMS_TDR_PHYS_vol1,
	author = {Collaboration, \cms  },
	citeulike-article-id = {773248},
	journal = {CERN/LHCC},
	keywords = {cms tau},
	number = {CMS TDR 8.1},
	priority = {2},
	title = {The CMS Physics Technical Design Report, Volume 1},
	volume = {2006-001},
	year = {2006}
}



@inproceedings{barrass2004sad,
	author = {Barras, Tim   and Al, Et  },
	booktitle = {Proceedings of CHEP04, Interlaken, Switzerland},
	citeulike-article-id = {623363},
	keywords = {cms computing dc04},
	month = {September},
	priority = {2},
	title = {Software agents in data and workflow management},
	url = {http://cms-project-phedex.web.cern.ch/cms-project-phedex/Documents/phedex-chep04.pdf},
	year = {2004}
}



@inproceedings{baud2004eld,
	author = {Baud, J. P.  and Casey, J. },
	booktitle = {Proceedings of CHEP04, Interlaken, Switzerland, September},
	citeulike-article-id = {623297},
	keywords = {grid},
	priority = {2},
	title = {Evolution of LCG-2 Data Management},
	url = {http://indico.cern.ch/getFile.py/access?contribId=278\&#38;sessionId=7\&#38;resId=0\&#38;materialId=paper\&#38;confId=0},
	year = {2004}
}



@inproceedings{citeulike:623295,
	abstract = {The Large Hadron Collider (LHC) at CERN, the European Organisation for Nuclear Research, will produce unprecedented volumes of data when it starts operation in 2007. To provide for its computational needs, the LHC Computing Grid (LCG) is being deployed as a worldwide computational grid service, providing the middleware upon which the physics analysis for the LHC will be carried out.

Data management middleware will be a key component of the LCG, enabling users to analyse their data without reference to the complex details of the computing environment.

In this paper we review the performance tests of the LCG File Catalog (LFC) and make comparisons with other data management catalogs. We also survey the deployment status of the LFC within the LCG.},
	author = {Baud, Jean-Philippe  B.  and Caey, James   and Lemaitre, Sophie   and Nicholson, Caitriana   and Smith, David   and Stewart, Graeme  },
	booktitle = {UK e-Science All Hands Meeting, Nottingham, UK},
	citeulike-article-id = {623295},
	keywords = {grid},
	priority = {2},
	title = {LCG Data Management: From EDG to EGEE},
	url = {http://ppewww.ph.gla.ac.uk/preprints/2005/06/},
	year = {2005}
}



@inproceedings{citeulike:623294,
	author = {Girone, M.  and Al, Et  },
	booktitle = {Computing in High-Energy Physics (CHEP '04), Interlaken, Switzerland},
	citeulike-article-id = {623294},
	keywords = {grid},
	priority = {2},
	title = {EXPERIENCE WITH POOL IN THE LCG DATA CHALLENGES OF THREE LHC EXPERIMENTS}
}



@proceedings{citeulike:623289,
	abstract = {The POOL project, as a part of the LHC Computing Grid (LCG), is now entering its third year of active development POOL provides the baseline persistency framework for three LHC experiment and is based on a strict component model, insulating experiment software from a variety of storage technology choices. This paper gives a brief overview of the POOL architecture, its main design principles and the experience gained with integration into LHC experiment frameworks. In also presents recent developments in the area of relational database abstraction and object storage into RDBMS systems.},
	author = {Chytracek, R.  and Dullmann, D.  and Frank, M.  and Girone, M.  and Govi, G.  and Moscicki, J. T.  and Papadopoulos, I.  and Schmuecker, H.  and Karr, K.  and Malon, D.  and Vaniachine, A.  and Tanenbaum, W.  and Xie, Z.  and Barrass, T.  and Cioffi, C. },
	citeulike-article-id = {623289},
	journal = {Nuclear Science Symposium Conference Record, 2004 IEEE},
	keywords = {computing grid},
	pages = {2077--2081 Vol. 4},
	priority = {2},
	title = {LCG POOL development status and production experience},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1462672},
	volume = {4},
	year = {2004}
}



@article{citeulike:623288,
	abstract = {Within the European DataGrid project, Work Package 2 has designed and implemented a set of integrated replica management services for use by data intensive scientific applications. These services, based on the web services model, enable movement and replication of data at high speed from one geographical site to another, management of distributed replicated data, optimization of access to data, and the provision of a metadata management tool. In this paper we describe the architecture and implementation of these services and evaluate their performance under demanding Grid conditions.},
	author = {Cameron, D.  and Al, Et  },
	citeulike-article-id = {623288},
	doi = {10.1007/s10723-004-5745-x},
	editor = {Laure, E. },
	journal = {Journal of Grid Computing},
	keywords = {computing grid},
	number = {4},
	pages = {341--351},
	priority = {2},
	title = {Replica Management in the European DataGrid Project},
	url = {http://dx.doi.org/10.1007/s10723-004-5745-x},
	volume = {2}
}



@article{citeulike:430964,
	abstract = {. If UML activity diagrams are to succeed as a standard in

the area of organisational process modeling, they need to compare well

to alternative languages such as those provided by commercial Workflow

Management Systems. This paper examines the expressiveness and the

adequacy of activity diagrams for workflow specification, by systematically

evaluating their ability to capture a collection of workflow patterns.

This analysis provides insights into the relative strengths and weaknesses

of ...},
	author = {Dumas, Marlon   and },
	citeulike-article-id = {430964},
	journal = {Lecture Notes in Computer Science},
	keywords = {uml},
	pages = {76--??},
	priority = {2},
	title = {UML Activity Diagrams as a Workflow Specification Language},
	url = {http://citeseer.ist.psu.edu/dumas01uml.html},
	volume = {2185},
	year = {2001}
}



@inproceedings{Fanfani:2004gh,
	author = {Fanfani, A. },
	booktitle = {Proceedings of CHEP04, Interlaken, Switzerland},
	citeulike-article-id = {623045},
	keywords = {cms computing dc04 grid},
	priority = {2},
	title = {Distributed computing grid experiences in CMS data challenge}
}



@inproceedings{citeulike:623034,
	abstract = {In order to prepare the Physics Technical Design Report, due by end of 2005, the CMS experiment needs to simulate, reconstruct and analyse about 100 million events, corresponding to more than 200 TB of data. The data will be distributed to several Computing Centres. In order to provide access to the whole data sample to all the world-wide dispersed physicists, CMS is developing a layer of software that uses the Grid tools provided by the LCG project to gain access to data and resources and that aims to provide a user friendly interface to the physicists submitting the analysis jobs. To achieve these aims CMS will use Grid tools from both the LCG-2 release and those being developed in the framework of the ARDA project. This work describes the current status and the future developments of the CMS analysis system.},
	author = {Andreeva, J.  and Anjum, A.  and Barrass, T.  and Bonacorsi, D.  and Bunn, J.  and Corvo, M.  and Darmenov, N.  and De Filippis, N.  and Donno, F.  and Donvito, G.  and Eulisse, G.  and Fanfani, A.  and Fanzago, F.  and Filine, A.  and Grandi, C.  and Hernandez, J. M.  and Innocente, V.  and Jan, A.  and Lacaprara, S.  and Legrand, I.  and Metson, S.  and Newman, H.  and Pierro, A.  and Silvestris, L.  and Steenberg, C.  and Stockinger, H.  and Taylor, L.  and Thomas, M.  and Tuura, L.  and Wildish, T.  and Van Lingen, F. },
	booktitle = {Nuclear Science Symposium Conference Record},
	citeulike-article-id = {623034},
	journal = {Nuclear Science Symposium Conference Record, 2004 IEEE},
	keywords = {cms computing dc04 grid},
	pages = {2029--2032 Vol. 4},
	priority = {2},
	title = {Use of grid tools to support CMS distributed analysis},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1462662},
	volume = {4},
	year = {2004}
}



@article{citeulike:621630,
	abstract = {The CMS experiment is currently developing a computing system capable of serving, processing and archiving the large number of events that will be generated when the CMS detector starts taking data. During 2004 CMS undertook a large scale data challenge to demonstrate the ability of the CMS computing system to cope with a sustained data-taking rate equivalent to 25% of startup rate. Its goals were: to run CMS event reconstruction at CERN for a sustained period at 25 Hz input rate; to distribute the data to several regional centers; and enable data access at those centers for analysis. Grid middleware was utilized to help complete all aspects of the challenge. To continue to provide scalable access from anywhere in the world to the data, CMS is developing a layer of software that uses Grid tools to gain access to data and resources, and that aims to provide physicists with a user friendly interface for submitting their analysis jobs. This paper describes the data challenge experience with Grid infrastructure and the current development of the CMS analysis system.},
	author = {Andreeva, J.  and Anjum, A.  and Barrass, T.  and Bonacorsi, D.  and Bunn, J.  and Capiluppi, P.  and Corvo, M.  and Darmenov, N.  and Defilippis, N.  and Donno, F.  and Donvito, G.  and Eulisse, G.  and Fanfani, A.  and Fanzago, F.  and Filine, A.  and Grandi, C.  and Hernandez, J. M.  and Innocente, V.  and Jan, A.  and Lacaprara, S.  and Legrand, I.  and Metson, S.  and Newman, H.  and Newbold, D.  and Pierro, A.  and Silvestris, L.  and Steenberg, C.  and Stockinger, H.  and Taylor, L.  and Thomas, M.  and Tuura, L.  and Wildish, T.  and Vanlingen, F. },
	citeulike-article-id = {621630},
	journal = {Nuclear Science, IEEE Transactions on},
	keywords = {boss cms computing dc04 grid},
	number = {4},
	pages = {884--890},
	priority = {2},
	title = {Distributed Computing Grid Experiences in CMS},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1495779},
	volume = {52},
	year = {2005}
}



@misc{citeulike:566861,
	abstract = {We present a first study of the channel H, A -\&gt; tau+tau -\&gt; h+ + h- + X in CMS
at high m(A) values where no triggering difficulties are expected with QCD
jets. At present the tau selection is based solely on the presence of a hard
isolated track in the "tau" jet, but further refinements based on calorimeter
collimation or impact parameter selections are obviously possible. The main
irreducible background in these conditions is due to QCD jets with hard
fragmentations. A large reduction of this background and improvement in the
expected signal to background ratio is provided by Etmiss cuts. The expected
high-mass reach in the m(A) tan(beta) parameter space for 3 x 10**4pb**-1 is
shown. This H -\&gt; tau+tau channel provides the highest mass reach and the best
mass resolution when compared to tau,tau -\&gt; lepton+hadron + Xand tau,tau -\&gt;
electton + muon + X final states. To the extent that with further calorimetric
and impact parameter based selection criteria the QCD background can be kept
under control, i.e. below the irreducible Z,gamma* -\&gt; tau+tau background, we
should strive to have a first level trigger allowing to explore the mass range
down to ~ 150 - 200 GeV.},
	author = {Kinnunen, R.  and Denegri, D. },
	citeulike-article-id = {566861},
	eprint = {hep-ph/9907291},
	keywords = {higgs mssm supersymmetry tau},
	month = {Jul},
	priority = {2},
	title = {H(SUSY)-\&gt;tau+tau-\&gt;hadron+hadron channel, its advantages and potential instrumental drawbacks},
	url = {http://arxiv.org/abs/hep-ph/9907291},
	year = {1999}
}



@misc{citeulike:566821,
	abstract = {The correlation between the two $\tau$-polarisations is predicted to be
opposite $(+-/-+)$ for the $H/A \to \tau^+\tau^-$ signal, while it corresponds
to the same sign combinations for the Drell-Yan $(++/--)$ and $t \bar t$ $(--)$
backgrounds. We show that this correlation can serve as a distinctive test to
confirm the presence of the MSSM Higgs bosons $H$ and $A$ in their hadronic
$\tau^+\tau^-$ decay channels at the LHC.},
	author = {Moretti, S.  and Roy, D. P. },
	citeulike-article-id = {566821},
	eprint = {hep-ph/0206206},
	keywords = {higgs mssm supersymmetry tau},
	month = {Sep},
	priority = {2},
	title = {The $\tau$-polarisation test for the $H/A\to\tau^+\tau^-$ signal at the LHC},
	url = {http://arxiv.org/abs/hep-ph/0206206},
	year = {2002}
}



@misc{citeulike:557241,
	abstract = {The CMS collaboration has a long term need to perform large-scale simulation
efforts, in which physics events are generated and their manifestations in the
CMS detector are simulated. Simulated data are then reconstructed and analyzed
by the physicists to support detector design and the design of the real-time
event filtering algorithms that will be used when CMS is running. Up to year
2002 the distribution of tasks among the different regional centers has been
done mainly through manual operations, even though some tools for data transfer
and centralization of the book-keeping were developed. In 2002 the first
prototypes of CMS distributed productions based on grid middleware have been
deployed, demonstrating that it is possible to use them for real data
production tasks. In this work we present the plans of the CMS experiment for
building a production and analysis environment based on the grid technologies
in time for the next big Data Challenge, which is foreseen for the beginning of
year 2004.},
	author = {Grandi, C. },
	citeulike-article-id = {557241},
	eprint = {hep-ex/0305099},
	keywords = {cms grid},
	month = {May},
	priority = {2},
	title = {Plans for the Integration of grid tools in the CMS computing environment},
	url = {http://arxiv.org/abs/hep-ex/0305099},
	year = {2003}
}



@book{citeulike:115158,
	abstract = {{<I>Design Patterns</I> is a modern classic in the literature of object-oriented development, offering timeless and elegant solutions to common problems in software design. It describes patterns for managing object creation, composing objects into larger structures, and coordinating control flow between objects. The book provides numerous examples where using composition rather than inheritance can improve the reusability and flexibility of code. Note, though, that it's not a tutorial but a catalog that you can use to find an object-oriented design pattern that's appropriate for the needs of your particular application--a selection for virtuoso programmers who appreciate (or require) consistent, well-engineered object-oriented designs.} {Now on CD, this internationally acclaimed bestseller is more valuable than ever! <P> Use the contents of the CD to create your own design documents and reusable components. The CD contains: 23 patterns you can cut and paste into your own design documents; sample code demonstrating pattern implementation; complete Design Patterns content in standard HTML format, with numerous hyperlinked cross-references; accessed through a standard web browser; Java-based dynamic search mechanism, enhancing online seach capabilities; graphical user environment, allowing ease of navigation. <P> First published in 1995, this landmark work on object-oriented software design presents a catalog of simple and succinct solutions to common design problems. Created by four experienced designers, the 23 patterns contained herein have become an essential resource for anyone developing reusable object-oriented software. In response to reader demand, the complete text and pattern catalog are now available on CD-ROM. This electronic version of <i>Design Patterns</i> enables programmers to install the book directly onto a computer or network for use as an online reference for creating reusable object-oriented software. <P> The authors first describe what patterns are and how they can help you in the design process. They then systematically name, explain, evaluate, and catalog recurring designs in object-oriented systems. All patterns are compiled from real-world examples and include code that demonstrates how they may be implemented in object-oriented programming languages such as C++ and Smalltalk. Readers who already own the book will want the CD to take advantage of its dynamic search mechanism and ready-to-install patterns.}},
	author = {Gamma, Erich   and Helm, Richard   and Johnson, Ralph   and Vlissides, John  },
	citeulike-article-id = {115158},
	howpublished = {Hardcover},
	isbn = {0201633612},
	keywords = {computing patterns},
	month = {January},
	priority = {0},
	publisher = {{Addison-Wesley Professional}},
	title = {Design Patterns},
	url = {http://www.amazon.co.uk/exec/obidos/ASIN/0201633612/citeulike-21},
	year = {1995}
}



@inproceedings{citeulike:363715,
	author = {Brun, Rene   and Rademakers, Fons  },
	booktitle = {AIHENP'96 Workshop, Lausane},
	citeulike-article-id = {363715},
	howpublished = {http://root.cern.ch/},
	journal = {Nucl. Inst. \& Meth. in Phys. Res. A},
	keywords = {computing},
	pages = {81--86},
	priority = {0},
	title = {ROOT - An Object Oriented Data Analysis Framework,},
	volume = {389},
	year = {1997}
}



@misc{citeulike:363705,
	citeulike-article-id = {363705},
	journal = {http://cmsdoc.cern.ch/orca/},
	keywords = {cms computing},
	priority = {0},
	title = {Object-oriented Reconstruction for CMS Analysis}
}



@misc{citeulike:363700,
	citeulike-article-id = {363700},
	journal = {http://standards.ieee.org/regauth/posix/},
	keywords = {computing},
	priority = {1},
	title = {IEEE POSIX® Certification Authority}
}



@misc{citeulike:355307,
	abstract = {We contrast the experimental signatures of low energy supersymmetry and the
model of Universal Extra Dimensions and discuss various methods for their
discrimination at hadron colliders. We study the discovery reach of the
Tevatron and the LHC for level 2 Kaluza-Klein modes, which would indicate the
presence of extra dimensions. We find that with 100 ${\rm fb}^{-1}$ of data the
LHC will be able to discover the $\gamma_2$ and $Z_2$ KK modes as separate
resonances if their masses are below 2 TeV. We also investigate the possibility
to differentiate the spins of the superpartners and KK modes by means of the
asymmetry method of Barr.},
	author = {Datta, Aseshkrishna   and Kong, Kyoungchul   and Matchev, Konstantin  T. },
	citeulike-article-id = {355307},
	eprint = {hep-ph/0509246},
	keywords = {lhc mssm supersymmetry},
	month = {Sep},
	priority = {0},
	title = {Discrimination of Supersymmetry and Universal Extra Dimensions at Hadron Colliders},
	url = {http://arxiv.org/abs/hep-ph/0509246},
	year = {2005}
}



@article{citeulike:20904,
	author = {Sphicas, P. },
	citeulike-article-id = {20904},
	doi = {10.1016/S0920-5632(03)01424-5 },
	issn = {0920-5632},
	journal = {Nuclear Physics B - Proceedings Supplements},
	keywords = {cms higgs lhc mssm supersymmetry tau},
	month = {April},
	number = {unknown},
	pages = {298--317},
	priority = {3},
	publisher = {Elsevier Science},
	title = {Forward look at LHC physics},
	url = {http://dx.doi.org/10.1016/S0920-5632(03)01424-5 },
	volume = {117},
	year = {2003}
}



@misc{citeulike:342741,
	abstract = {BOSS (Batch Object Submission System) has been developed to provide real-time
monitoring and bookkeeping of jobs submitted to a compute farm system. The
information is persistently stored in a relational database (MySQL in the
current version) for further processing. By means of user-supplied filters,
BOSS extracts the specific job information to be monitored from the standard
input, output and error of the job itself and stores it in the database in a
structured form that allows easy and efficient access. BOSS has been
successfully used by all CMS Regional Centers for managing Monte Carlo data
productions in 2002. Furthermore in fall 2002 it has been used in a prototype
of the CMS production system deployed on the European DataGrid test bed
demonstrating its ability to be used also in a grid environment.},
	author = {Grandi, C. },
	citeulike-article-id = {342741},
	eprint = {hep-ex/0305098},
	keywords = {boss computing},
	month = {May},
	priority = {2},
	title = {BOSS: a tool for batch job monitoring and book-keeping},
	url = {http://arxiv.org/abs/hep-ex/0305098},
	year = {2003}
}



@article{CERN/LHCC-1999-045,
	author = {Collaboration, C. M. S. },
	citeulike-article-id = {342737},
	journal = {CERN/LHCC},
	keywords = {cms},
	priority = {2},
	title = {CMS, the Compact Muon Solenoid: Technical proposal},
	volume = {94-38},
	year = {1994}
}



@article{Aderholz:2000nk,
	author = {Aderholz, M. },
	citeulike-article-id = {342733},
	journal = {CERN/LCB},
	keywords = {computing grid lcg},
	priority = {2},
	title = {Models of Networked Analysis at Regional Centres for LHC Experiments (MONARC) - Phase 2 Report},
	volume = {2000-001},
	year = {2000}
}



@article{Dedovich:2005ss,
	abstract = {This paper presents results on the measurement of tau-lepton hadronic decays branching ratios in DELPHI experiments at LEP. It includes the final results on exclusive hadronic branchings (without [pi]/K separation) and preliminary results on single-prong tau-lepton decays to kaons.},
	author = {Dedovich, D. },
	citeulike-article-id = {342482},
	doi = {10.1016/j.nuclphysbps.2005.02.004},
	journal = {Nuclear Physics B - Proceedings Supplements},
	keywords = {decay delphi lep tau},
	month = {July},
	pages = {27--33},
	priority = {3},
	title = {Measurements of tau hadronic branching ratios in DELPHI experiment},
	url = {http://dx.doi.org/10.1016/j.nuclphysbps.2005.02.004},
	volume = {144},
	year = {2005}
}



@book{citeulike:340626,
	abstract = {{Beyond the Net, say Foster, Kesselman, and a host of impressive contributors, lies the Grid. While the Net allows users everywhere to share information, the Grid will allow users to share raw computing power. The goal is to put full supercomputing capabilities into the hands of anyone who needs it while providing for more efficient use of the supercomputers of tomorrow. The potential benefits to science, government, and business may well be beyond imagination.<p> Foster and Kesselman have gathered together essays, proposals, and ruminations of more than 30 distinguished stars of the high-speed computing and networking world in order to do four things: make the case for developing computational grids, provide ideas on how such grids may be designed, demonstrate how the grids might be used, and point out the research still needed to make it happen. While the book was written to serve as a possible textbook in advanced networking, it makes fascinating reading for anyone interested in the future of network computing.<p> The text covers Grid applications, the programming tools required, the services that will be provided, and an examination of Grid infrastructure. Despite being the work of so many authors, the chapters are logically arranged so that the knowledge needed to understand one chapter is provided by those that precede it. <I>--Elizabeth Lewis</I>} {The grid promises to fundamentally change the way we think about and use computing. This infrastructure will connect multiple regional and national computational grids, creating a universal source of pervasive and dependable computing power that supports dramatically new classes of applications. The Grid provides a clear vision of what computational grids are, why we need them, who will use them, and how they will be programmed.<br><br>Inside The Grid<br>*  Written by over 30 distinguished experts in high-performance computing and networking, including Francine Berman, Tom DeFanti, Jack Dongarra, Dennis Gannon, Roch Guerin, Ken Kennedy, Miron Livny, Paul Messina, Reagan Moore, Clifford Neuman, Larry Peterson, Jon Postel, and Daniel Reed.<br><br>*  Edited by the winners of the prestigious 1998 Global Information Infrastructure Next Generation Award\&#195;\&#162;\&#194;\&#128;\&#194;\&#148;an awards program characterized by U.S. Vice President Al Gore as "confirm[ing] our brightest hopes: that the positive uses of high technology will truly open up new opportunities for all Americans and improve our quality of life."<br><br>*  Introduced by Larry Smarr, director of National Center for Supercomputing Applications and director of the National Computational Science Alliance, with a chapter that puts grids in context.}},
	author = {Kesselman, Carl   and Foster, Ian  },
	citeulike-article-id = {340626},
	howpublished = {Hardcover},
	isbn = {1558604758},
	keywords = {computing grid},
	month = {November},
	priority = {1},
	publisher = {{Morgan Kaufmann Publishers}},
	title = {The Grid: Blueprint for a New Computing Infrastructure},
	url = {http://www.amazon.co.uk/exec/obidos/ASIN/1558604758/citeulike-21},
	year = {1998}
}



@misc{CERN/LHCC/2002-26,
	citeulike-article-id = {340576},
	keywords = {cms computing},
	priority = {2},
	title = {CMS, The TRIDAS Project, Technical Design Report Volume 2; Data Acquisition and Higher Level Trigger},
	volume = {CERN/LHCC/2002-26}
}



@misc{CMS_COMPTDR,
	author = {Collaboration, \cms  },
	citeulike-article-id = {340566},
	journal = {CERN/LHCC},
	keywords = {cms computing},
	number = {CMS TDR 7},
	priority = {0},
	title = {CMS, The Computing Project, Technical Design Report},
	volume = {2005-23},
	year = {2005}
}



@misc{hep-ph/0203187,
	abstract = {We review the theoretical status of signal and background calculations for Higgs boson production at hadron colliders. Particular emphasis is given to missing NLO results, which will play a crucial role for the Tevatron and the LHC.},
	author = {Rainwater, David   and Spira, Michael   and Zeppenfeld, Dieter  },
	citeulike-article-id = {340430},
	eprint = {hep-ph/0203187},
	keywords = {higgs lhc},
	month = {Mar},
	priority = {0},
	title = {Higgs Boson Production at Hadron Colliders: Signal and Background Processes},
	url = {http://arxiv.org/abs/hep-ph/0203187},
	year = {2002}
}



@article{hep-ph/9808468,
	author = {Rainwater, D.  and Zeppenfeld, D.  and Hagiwara, K. },
	citeulike-article-id = {340424},
	journal = {Phys.Rev.},
	keywords = {higgs lhc tau},
	pages = {014--037},
	priority = {2},
	title = {Searching for H --> tau tau in weak boson fusion at the LHC},
	url = {http://arxiv.org/abs/hep-ph/?9808468},
	volume = {D59},
	year = {1999}
}



@misc{hep-ex/0412023,
	abstract = {I outline recent results using CLEO3 data involving the decay of the tau to three charged hadrons and a neutrino, as well as an investigation of the structure of the decay tau to KKpinu and the Wess-Zumino term in this decay.},
	author = {Duboscq, J. E. },
	citeulike-article-id = {340423},
	eprint = {hep-ex/0412023},
	keywords = {cleo decay tau},
	month = {Dec},
	priority = {2},
	title = {Recent CLEO Results on Tau Hadronic Decays},
	url = {http://arxiv.org/abs/hep-ex/0412023},
	year = {2004}
}



@article{CERN-LCG-2003-033,
	abstract = {This document is the report of the LHC Computing Grid Project's Requirements and Technical
Assessment Group (RTAG) on an “Architectural Roadmap for Distributed Analysis” (ARDA).},
	citeulike-article-id = {340365},
	journal = {CERN-LCG-2003-033},
	keywords = {analysis arda computing},
	month = {October},
	priority = {1},
	title = {ARDA RTAG Report, Architectural Roadmap for Distributed Analysis},
	url = {http://lcg.web.cern.ch/lcg/PEB/arda/public_docs/ARDA_report_final.pdf},
	year = {2003}
}



@article{LHC-SC2-20-2002,
	abstract = {This document overviews analysis activities and possible execution models, and identifies common use cases for LHC applications to use grid services for data analysis. In addition the characteristics of interactive vs. batch grid activities are presented, and some special system requirements on middleware are itemised, with key areas being the support of provenance, general reporting facilities, ‘persistent’ interactive work, and analysis software development.},
	citeulike-article-id = {340358},
	editor = {Carminati, F.  and Templon, J. },
	journal = {LHC-SC2-20-2002},
	keywords = {analysis lcg},
	month = {October},
	priority = {2},
	title = {LHC Grid Computing Project: COMMON USE CASES FOR A HEP COMMON APLLICATION LAYER FOR ANALYSIS (HEPCAL)},
	url = {http://project-lcg-gag.web.cern.ch/project-lcg-gag/LCG_GAG_Docs/HEPCAL-II.pdf},
	year = {2003}
}



@article{CMSNOTE_2004-031,
	abstract = {This paper describes the top-level requirements and specifications of the CMS Computing Model, and the associated costs. It was prepared primarily for the LHCC review of Computing Resources of January 2005 but will also be used as input to the CMS and LCG Computing TDR's, due for submission in the Summer of 2005. The primary focus is the first year of LHC physics running but approximate estimates of the cost evolution are also given.},
	citeulike-article-id = {340343},
	editor = {Grandi, C.  and Stickland, D.  and Taylor, L. },
	journal = {CMS NOTE},
	keywords = {cms computing grid},
	month = {December},
	priority = {0},
	title = {CMS Computing Model : The ``CMS Computing Model RTAG''},
	url = {http://cdsweb.cern.ch/search.py?recid=814248\&#38;ln=en},
	volume = {2004-031},
	year = {2004}
}



@misc{hep-ex/0506042,
	abstract = {A search for direct production of Higgs bosons in the di-tau decay mode is performed with 86.3 +/- 3.5 pb^-1 of data collected with the Collider Detector at Fermilab during the 1994-1995 data taking period of the Tevatron. We search for events where one tau decays to an electron plus neutrinos and the other tau decays hadronically. We perform a counting experiment and set limits on the cross section for supersymmetric Higgs boson production where tan(beta) is large and m_A is small. For a benchmark parameter space point where m_A=100 GeV/c^2 and tan(beta)=50, we limit the production cross section multiplied by the branching ratio to be less than 77.9 pb at the 95% confidence level compared to the theoretically predicted value of 11.0 pb. This is the first search for Higgs bosons decaying to tau pairs at a hadron collider.},
	author = {Collaboration, C. D. F.  and Acosta, D. },
	citeulike-article-id = {339636},
	eprint = {hep-ex/0506042},
	keywords = {cdf higgs mssm supersymmetry},
	month = {Jun},
	priority = {0},
	title = {A Search for Supersymmetric Higgs Bosons in the Di-Tau Decay Mode in Proton Anti-Proton Collisions at sqrt(s)=1.8 TeV},
	url = {http://arxiv.org/abs/hep-ex/0506042},
	year = {2005}
}



@inproceedings{CHEP04_TALLINI,
	abstract = {GROSS (GRidified Orca Submission System) has been developed to provide CMS end users with a single interface for running batch analysis tasks over the LCG-2 Grid. The main purpose of the tool is to carry out job splitting, preparation, submission, monitoring and archiving in a transparent way which is simple to use for the end user. Central to its design has been the requirement for allowing multi-user analyses, and to accomplish this all persistent information is stored on a backend MySQL database. This database is additionally shared with BOSS, to which GROSS interfaces in order to provide job submission and real time monitoring capability. In this paper we present an overview of GROSS's architecture and functionality and report on first user tests of the system using CMS Data Challenge 2004 data (DC04).},
	author = {Tallini, H.  and Colling, D.  and Macevoy, B.  and Wakefield, S. },
	booktitle = {Proceedings of CHEP04, Interlaken, Switzerland},
	citeulike-article-id = {339479},
	keywords = {analysis computing grid gross},
	priority = {0},
	title = {GROSS: an end user tool for carrying out batch analysis of CMS data on the LCG-2 Grid.},
	url = {http://indico.cern.ch/contributionDisplay.py?contribId=148\&#38;sessionId=23\&#38;confId=0},
	year = {2004}
}



@article{citeulike:339476,
	author = {Lloyd, S. L. },
	citeulike-article-id = {339476},
	journal = {Physics World},
	keywords = {computing grid lcg},
	priority = {0},
	title = {Building the next IT revolution (October 2003) - Physics World - PhysicsWeb},
	url = {http://physicsweb.org/articles/world/16/10/3},
	volume = {October},
	year = {2003}
}



@article{hep-ex/0506072,
	author = {Collaboration, Aleph  },
	citeulike-article-id = {339472},
	keywords = {aleph lep tau},
	priority = {2},
	title = {Branching ratios and spectral functions of tau decays: final ALEPH measurements and physics implications},
	url = {http://citebase.eprints.org/cgi-bin/citations?id=oai:arXiv.org:hep-ex/0506072}
}



@article{hep-ph/0503067,
	author = {Kinnunen, R.  and Lehti, S.  and Nikitenko, A.  and Salmi, P. },
	citeulike-article-id = {35212},
	doi = {10.1088/0954-3899/31/2/001},
	issn = {0954-3899},
	journal = {Journal of Physics G: Nuclear and Particle Physics},
	keywords = {higgs lhc mssm supersymmetry},
	number = {2},
	pages = {71+},
	priority = {2},
	publisher = {Institute of Physics Publishing},
	title = {On the discovery potential of the lightest MSSM Higgs boson at the LHC},
	url = {http://dx.doi.org/10.1088/0954-3899/31/2/001},
	volume = {31}
}



@misc{hep-ex/0508051,
	abstract = {We present a search for neutral supersymmetric Higgs bosons decaying to tau pairs produced in p-pbar collisions at sqrt(s) = 1.96 TeV. The data, corresponding to 310 pb^(-1) integrated luminosity, were collected with the CDF II detector at the Tevatron collider at Fermilab. No significant excess above the standard model backgrounds is observed. We set exclusion limits on the production cross section times branching fraction to tau pairs for Higgs masses in the range from 90 to 250 GeV/c^2.},
	author = {Collaboration, C. D. F. },
	citeulike-article-id = {339463},
	eprint = {hep-ex/0508051},
	keywords = {cdf higgs mssm supersymmetry tau},
	month = {Aug},
	priority = {3},
	title = {Search for neutral MSSM Higgs bosons decaying to tau pairs in p-pbar collisions at sqrt(s)=1.96 TeV},
	url = {http://arxiv.org/abs/hep-ex/0508051},
	year = {2005}
}




